===============to start hbase===========================================
go to :		/home/ist/Documents/downloads/hbase/hbase-1.2.2/bin
type:		./start-hbase.sh
type:		./hbase shell

===============create=============
create 'student','r'

===============insert=============
put 'student','rowKey','r:name','mithlesh'

===============delete=============
delete 'student','rowKey','r:name'

===============update=============
put 'student','rowey','r:city','indore'

===============create===============
create 'student' , 'r',  COMPRESSION => 'SNAPPY' , SPLITS =>['00','01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45','46','47','48','49','50']

============dump of hbase===========================
echo "scan 'student', TIMERANGE=>[1531074600000,1531679400000], COLUMN=>['r:gL3','r:gL4','r:routeHolderList']" | hbase shell > dump2.csv

============column value filter======================
scan 'student', { COLUMNS => 'r:vCallToken', FILTER => "ValueFilter( =, 'binaryprefix:hold-unhold-test1' )" }

============ragex value filter=======================
scan 'student', { FILTER => "RowFilter(=, 'regexstring:5junecall')" }

============startrow endrow filter===================
scan 'student', {STARTROW => 'abc', ENDROW => 'abd'}

============export data from hbase table===============
hbase org.apache.hadoop.hbase.mapreduce.Export  -Dmapreduce.job.queuename=ingest  "TableName" "/user/userapp/path"

============import data from hbase table===============
hbase org.apache.hadoop.hbase.mapreduce.Import "TableName" "/user/userapp/path"

==================export with timerange=================================================
hbase org.apache.hadoop.hbase.mapreduce.Export -Dmapreduce.job.queuename='ingest'  'TableName' hdfs:///user/userapp/temp2/ 1000 1558433604633 1558434179173

